{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. In Chapter 4, we used logistic regression to predict the probability of\n",
    "default using income and balance on the Default data set. We will\n",
    "now estimate the test error of this logistic regression model using the\n",
    "validation set approach. Do not forget to set a random seed before\n",
    "beginning your analysis.\n",
    "(a) Fit a logistic regression model that uses income and balance to\n",
    "predict default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['default', 'student', 'balance', 'income'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ISLP import load_data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ISLP\n",
    "import numpy as np\n",
    "from statsmodels.api import GLM\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "default = load_data('Default')\n",
    "default.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income\n",
       "0      No      No   729.526495  44361.625074\n",
       "1      No     Yes   817.180407  12106.134700\n",
       "2      No      No  1073.549164  31767.138947\n",
       "3      No      No   529.250605  35704.493935\n",
       "4      No      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-11.54046792])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = default[['balance','income']]\n",
    "y = default['default']\n",
    "def_logreg = LogisticRegression()\n",
    "def_logreg.fit(X,y)\n",
    "def_logreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Using the validation set approach, estimate the test error of this\n",
    "model. In order to do this, you must perform the following steps:\n",
    "i. Split the sample set into a training set and a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_X_train, def_X_test, def_y_train, def_y_test = train_test_split(X,y,test_size=5000,random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Fit a multiple logistic regression model using only the training observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_logreg2 = LogisticRegression()\n",
    "def_logreg2.fit(def_X_train,def_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Obtain a prediction of default status for each individual in\n",
    "the validation set by computing the posterior probability of\n",
    "default for that individual, and classifying the individual to\n",
    "the default category if the posterior probability is greater\n",
    "than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'No', 'No', ..., 'No', 'No', 'No'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_logreg2_preds = def_logreg2.predict(def_X_test)\n",
    "def_logreg2_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. Compute the validation set error, which is the fraction of\n",
    "the observations in the validation set that are misclassified.\n",
    "\n",
    "- 2.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_logreg_test_error = np.mean(def_logreg2_preds!=def_y_test)\n",
    "def_logreg_test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Repeat the process in (b) three times, using three different splits\n",
    "of the observations into a training set and a validation set. Comment on the results obtained.\n",
    "\n",
    "- Since we are changing the training set, the validition error rate varies by using different training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_X_train, def_X_test, def_y_train, def_y_test = train_test_split(X,y,test_size=5000,random_state=1)\n",
    "def_logreg2 = LogisticRegression()\n",
    "def_logreg2.fit(def_X_train,def_y_train)\n",
    "def_logreg2_preds = def_logreg2.predict(def_X_test)\n",
    "def_logreg_test_error = np.mean(def_logreg2_preds!=def_y_test)\n",
    "def_logreg_test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0248"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_X_train, def_X_test, def_y_train, def_y_test = train_test_split(X,y,test_size=5000,random_state=2)\n",
    "def_logreg2 = LogisticRegression()\n",
    "def_logreg2.fit(def_X_train,def_y_train)\n",
    "def_logreg2_preds = def_logreg2.predict(def_X_test)\n",
    "def_logreg_test_error = np.mean(def_logreg2_preds!=def_y_test)\n",
    "def_logreg_test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Now consider a logistic regression model that predicts the probability of default using income, balance, and a dummy variable\n",
    "for student. Estimate the test error for this model using the validation set approach. Comment on whether or not including a\n",
    "dummy variable for student leads to a reduction in the test error\n",
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akbas\\AppData\\Local\\Temp\\ipykernel_6432\\4263682266.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['student01'] = Student01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>student01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>711.555020</td>\n",
       "      <td>52992.378914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>757.962918</td>\n",
       "      <td>19660.721768</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>845.411989</td>\n",
       "      <td>58636.156984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1569.009053</td>\n",
       "      <td>36669.112365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>200.922183</td>\n",
       "      <td>16862.952321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          balance        income  student01\n",
       "0      729.526495  44361.625074          0\n",
       "1      817.180407  12106.134700          1\n",
       "2     1073.549164  31767.138947          0\n",
       "3      529.250605  35704.493935          0\n",
       "4      785.655883  38463.495879          0\n",
       "...           ...           ...        ...\n",
       "9995   711.555020  52992.378914          0\n",
       "9996   757.962918  19660.721768          0\n",
       "9997   845.411989  58636.156984          0\n",
       "9998  1569.009053  36669.112365          0\n",
       "9999   200.922183  16862.952321          1\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Student01 = np.array(X.shape[0]*[0])\n",
    "Student01[default.student == 'Yes'] = 1\n",
    "X['student01'] = Student01\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0294"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_X_train, def_X_test, def_y_train, def_y_test = train_test_split(X,y,test_size=5000,random_state=0)\n",
    "def_logreg2 = LogisticRegression()\n",
    "def_logreg2.fit(def_X_train,def_y_train)\n",
    "def_logreg2_preds = def_logreg2.predict(def_X_test)\n",
    "def_logreg_test_error = np.mean(def_logreg2_preds!=def_y_test)\n",
    "def_logreg_test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It resulted in a slight increase compared to models without student info. However since there is a lot of variability because of validition set approach, it is difficult to state any improvements, or downgrades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. We continue to consider the use of a logistic regression model to\n",
    "predict the probability of default using income and balance on the\n",
    "Default data set. In particular, we will now compute estimates for the\n",
    "standard errors of the income and balance logistic regression coefficients in two different ways: (1) using the bootstrap, and (2) using the\n",
    "standard formula for computing the standard errors in the sm.GLM()\n",
    "function. Do not forget to set a random seed before beginning your\n",
    "analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akbas\\AppData\\Local\\Temp\\ipykernel_6432\\2468388698.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:,'intercept'] = 1;\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>default</td>     <th>  No. Observations:  </th>  <td> 10000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>  9997</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>Logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -789.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 13 Sep 2024</td> <th>  Deviance:          </th> <td>  1579.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:56:07</td>     <th>  Pearson chi2:      </th> <td>6.95e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>9</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.1256</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>    0.0056</td> <td>    0.000</td> <td>   24.835</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td> 2.081e-05</td> <td> 4.99e-06</td> <td>    4.174</td> <td> 0.000</td> <td>  1.1e-05</td> <td> 3.06e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>  -11.5405</td> <td>    0.435</td> <td>  -26.544</td> <td> 0.000</td> <td>  -12.393</td> <td>  -10.688</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &     default      & \\textbf{  No. Observations:  } &    10000    \\\\\n",
       "\\textbf{Model:}           &       GLM        & \\textbf{  Df Residuals:      } &     9997    \\\\\n",
       "\\textbf{Model Family:}    &     Binomial     & \\textbf{  Df Model:          } &        2    \\\\\n",
       "\\textbf{Link Function:}   &      Logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n",
       "\\textbf{Method:}          &       IRLS       & \\textbf{  Log-Likelihood:    } &   -789.48   \\\\\n",
       "\\textbf{Date:}            & Fri, 13 Sep 2024 & \\textbf{  Deviance:          } &    1579.0   \\\\\n",
       "\\textbf{Time:}            &     10:56:07     & \\textbf{  Pearson chi2:      } &  6.95e+03   \\\\\n",
       "\\textbf{No. Iterations:}  &        9         & \\textbf{  Pseudo R-squ. (CS):} &   0.1256    \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{balance}   &       0.0056  &        0.000     &    24.835  &         0.000        &        0.005    &        0.006     \\\\\n",
       "\\textbf{income}    &    2.081e-05  &     4.99e-06     &     4.174  &         0.000        &      1.1e-05    &     3.06e-05     \\\\\n",
       "\\textbf{intercept} &     -11.5405  &        0.435     &   -26.544  &         0.000        &      -12.393    &      -10.688     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Generalized Linear Model Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                default   No. Observations:                10000\n",
       "Model:                            GLM   Df Residuals:                     9997\n",
       "Model Family:                Binomial   Df Model:                            2\n",
       "Link Function:                  Logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -789.48\n",
       "Date:                Fri, 13 Sep 2024   Deviance:                       1579.0\n",
       "Time:                        10:56:07   Pearson chi2:                 6.95e+03\n",
       "No. Iterations:                     9   Pseudo R-squ. (CS):             0.1256\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "balance        0.0056      0.000     24.835      0.000       0.005       0.006\n",
       "income      2.081e-05   4.99e-06      4.174      0.000     1.1e-05    3.06e-05\n",
       "intercept    -11.5405      0.435    -26.544      0.000     -12.393     -10.688\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = default[['balance','income']]\n",
    "X.loc[:,'intercept'] = 1;\n",
    "y = default['default'] == 'Yes'\n",
    "default['default01'] = y\n",
    "def_logreg3 = GLM(y,X,family=sm.families.Binomial()).fit()\n",
    "\n",
    "def_logreg3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Write a function, boot_fn(), that takes as input the Default data\n",
    "set as well as an index of the observations, and that outputs\n",
    "the coefficient estimates for income and balance in the multiple\n",
    "logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_fn(response, D, idx):\n",
    "    D['default01'] = D['default01'].astype(int)\n",
    "    D_ = D.loc[idx]\n",
    "    Y_ = D_[response]\n",
    "    X = D_[['income','balance']]\n",
    "    X_ = sm.add_constant(X)\n",
    "    model = sm.Logit(Y_, X_)\n",
    "    result = model.fit(disp=0)\n",
    "    coefficients = result.params\n",
    "    income_coef = coefficients['income']\n",
    "    balance_coef = coefficients['balance']\n",
    "    \n",
    "    return (income_coef, balance_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Income Coefficient: 2.064480037071877e-05\n",
      "Average Balance Coefficient: 0.005661678039446398\n"
     ]
    }
   ],
   "source": [
    "def bootstrap_estimates(D, n_iterations=1000, sample_size=None):\n",
    "    rng = np.random.default_rng(0)  \n",
    "    income_coefs = []\n",
    "    balance_coefs = []\n",
    "    n = len(D)\n",
    "    if sample_size is None:\n",
    "        sample_size = n\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        idx = rng.choice(n, size=sample_size, replace=True)\n",
    "        \n",
    "        income_coef, balance_coef = boot_fn('default01',D, idx)\n",
    "        \n",
    "        income_coefs.append(income_coef)\n",
    "        balance_coefs.append(balance_coef)\n",
    "    \n",
    "    avg_income_coef = np.mean(income_coefs)\n",
    "    avg_balance_coef = np.mean(balance_coefs)\n",
    "    \n",
    "    return avg_income_coef, avg_balance_coef\n",
    "\n",
    "avg_income_coef, avg_balance_coef = bootstrap_estimates(default)\n",
    "print(f\"Average Income Coefficient: {avg_income_coef}\")\n",
    "print(f\"Average Balance Coefficient: {avg_balance_coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Following the bootstrap example in the lab, use your boot_fn()\n",
    "function to estimate the standard errors of the logistic regression\n",
    "coefficients for income and balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_std_errors(D, n_iterations=1000, sample_size=None):\n",
    "    rng = np.random.default_rng(0) \n",
    "    income_coefs = []\n",
    "    balance_coefs = []\n",
    "    \n",
    "    n = len(D)\n",
    "    if sample_size is None:\n",
    "        sample_size = n\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        idx = rng.choice(n, size=sample_size, replace=True)\n",
    "        income_coef, balance_coef = boot_fn('default01',D, idx)\n",
    "        income_coefs.append(income_coef)\n",
    "        balance_coefs.append(balance_coef)\n",
    "    \n",
    "    std_error_income = np.std(income_coefs, ddof=1)\n",
    "    std_error_balance = np.std(balance_coefs, ddof=1)\n",
    "    \n",
    "    return std_error_income, std_error_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Error of Income Coefficient: 4.769585138887178e-06\n",
      "Standard Error of Balance Coefficient: 0.00023055064733487824\n"
     ]
    }
   ],
   "source": [
    "std_error_income, std_error_balance = bootstrap_std_errors(default)\n",
    "print(f\"Standard Error of Income Coefficient: {std_error_income}\")\n",
    "print(f\"Standard Error of Balance Coefficient: {std_error_balance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Comment on the estimated standard errors obtained using the\n",
    "sm.GLM() function and using the bootstrap.\n",
    "\n",
    "- Standart error estimates from using bootstrap are very close to sm.GLM() function, but we expect bootstrap estimates to be closer to real standart error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. In Sections 5.1.2 and 5.1.3, we saw that the cross_validate() function\n",
    "can be used in order to compute the LOOCV test error estimate.\n",
    "Alternatively, one could compute those quantities using just sm.GLM()\n",
    "and the predict() method of the fitted model within a for loop. You\n",
    "will now take this approach in order to compute the LOOCV error\n",
    "for a simple logistic regression model on the Weekly data set. Recall\n",
    "that in the context of classification problems, the LOOCV error is\n",
    "given in (5.4).\n",
    "\n",
    "(a) Fit a logistic regression model that predicts Direction using Lag1\n",
    "and Lag2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-3.484</td>\n",
       "      <td>0.154976</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.148574</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>0.159837</td>\n",
       "      <td>3.514</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>0.161630</td>\n",
       "      <td>0.712</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.712</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>1.178</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>2010</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>3.599</td>\n",
       "      <td>0.015</td>\n",
       "      <td>3.205160</td>\n",
       "      <td>2.969</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>2010</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>3.599</td>\n",
       "      <td>4.242568</td>\n",
       "      <td>1.281</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>2010</td>\n",
       "      <td>1.281</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>4.835082</td>\n",
       "      <td>0.283</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.283</td>\n",
       "      <td>1.281</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4.454044</td>\n",
       "      <td>1.034</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>2010</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.283</td>\n",
       "      <td>1.281</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>2.707105</td>\n",
       "      <td>0.069</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1089 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume  Today Direction\n",
       "0     1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976 -0.270      Down\n",
       "1     1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574 -2.576      Down\n",
       "2     1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837  3.514        Up\n",
       "3     1990  3.514 -2.576 -0.270  0.816  1.572  0.161630  0.712        Up\n",
       "4     1990  0.712  3.514 -2.576 -0.270  0.816  0.153728  1.178        Up\n",
       "...    ...    ...    ...    ...    ...    ...       ...    ...       ...\n",
       "1084  2010 -0.861  0.043 -2.173  3.599  0.015  3.205160  2.969        Up\n",
       "1085  2010  2.969 -0.861  0.043 -2.173  3.599  4.242568  1.281        Up\n",
       "1086  2010  1.281  2.969 -0.861  0.043 -2.173  4.835082  0.283        Up\n",
       "1087  2010  0.283  1.281  2.969 -0.861  0.043  4.454044  1.034        Up\n",
       "1088  2010  1.034  0.283  1.281  2.969 -0.861  2.707105  0.069        Up\n",
       "\n",
       "[1089 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly =load_data('Weekly')\n",
    "weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Direction</td>    <th>  No. Observations:  </th>  <td>  1089</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>  1086</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>Logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -744.11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 13 Sep 2024</td> <th>  Deviance:          </th> <td>  1488.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:56:27</td>     <th>  Pearson chi2:      </th> <td>1.09e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>4</td>        <th>  Pseudo R-squ. (CS):</th> <td>0.007303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.2212</td> <td>    0.061</td> <td>    3.599</td> <td> 0.000</td> <td>    0.101</td> <td>    0.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag1</th>  <td>   -0.0387</td> <td>    0.026</td> <td>   -1.477</td> <td> 0.140</td> <td>   -0.090</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag2</th>  <td>    0.0602</td> <td>    0.027</td> <td>    2.270</td> <td> 0.023</td> <td>    0.008</td> <td>    0.112</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &    Direction     & \\textbf{  No. Observations:  } &     1089    \\\\\n",
       "\\textbf{Model:}           &       GLM        & \\textbf{  Df Residuals:      } &     1086    \\\\\n",
       "\\textbf{Model Family:}    &     Binomial     & \\textbf{  Df Model:          } &        2    \\\\\n",
       "\\textbf{Link Function:}   &      Logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n",
       "\\textbf{Method:}          &       IRLS       & \\textbf{  Log-Likelihood:    } &   -744.11   \\\\\n",
       "\\textbf{Date:}            & Fri, 13 Sep 2024 & \\textbf{  Deviance:          } &    1488.2   \\\\\n",
       "\\textbf{Time:}            &     10:56:27     & \\textbf{  Pearson chi2:      } &  1.09e+03   \\\\\n",
       "\\textbf{No. Iterations:}  &        4         & \\textbf{  Pseudo R-squ. (CS):} &  0.007303   \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       0.2212  &        0.061     &     3.599  &         0.000        &        0.101    &        0.342     \\\\\n",
       "\\textbf{Lag1}  &      -0.0387  &        0.026     &    -1.477  &         0.140        &       -0.090    &        0.013     \\\\\n",
       "\\textbf{Lag2}  &       0.0602  &        0.027     &     2.270  &         0.023        &        0.008    &        0.112     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Generalized Linear Model Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:              Direction   No. Observations:                 1089\n",
       "Model:                            GLM   Df Residuals:                     1086\n",
       "Model Family:                Binomial   Df Model:                            2\n",
       "Link Function:                  Logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -744.11\n",
       "Date:                Fri, 13 Sep 2024   Deviance:                       1488.2\n",
       "Time:                        10:56:27   Pearson chi2:                 1.09e+03\n",
       "No. Iterations:                     4   Pseudo R-squ. (CS):           0.007303\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.2212      0.061      3.599      0.000       0.101       0.342\n",
       "Lag1          -0.0387      0.026     -1.477      0.140      -0.090       0.013\n",
       "Lag2           0.0602      0.027      2.270      0.023       0.008       0.112\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_X = weekly[['Lag1','Lag2']]\n",
    "weekly_X = sm.add_constant(weekly_X)\n",
    "weekly_y = weekly['Direction'] == 'Up'\n",
    "weekly_logreg = sm.GLM(weekly_y,weekly_X,family=sm.families.Binomial())\n",
    "weekly_results = weekly_logreg.fit()\n",
    "weekly_results.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Fit a logistic regression model that predicts Direction using Lag1\n",
    "and Lag2 using all but the first observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Direction</td>    <th>  No. Observations:  </th>  <td>  1087</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>  1084</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>Logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -742.42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 13 Sep 2024</td> <th>  Deviance:          </th> <td>  1484.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:56:27</td>     <th>  Pearson chi2:      </th> <td>1.09e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>4</td>        <th>  Pseudo R-squ. (CS):</th> <td>0.007440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.2254</td> <td>    0.062</td> <td>    3.663</td> <td> 0.000</td> <td>    0.105</td> <td>    0.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag1</th>  <td>   -0.0386</td> <td>    0.026</td> <td>   -1.472</td> <td> 0.141</td> <td>   -0.090</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag2</th>  <td>    0.0611</td> <td>    0.027</td> <td>    2.300</td> <td> 0.021</td> <td>    0.009</td> <td>    0.113</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &    Direction     & \\textbf{  No. Observations:  } &     1087    \\\\\n",
       "\\textbf{Model:}           &       GLM        & \\textbf{  Df Residuals:      } &     1084    \\\\\n",
       "\\textbf{Model Family:}    &     Binomial     & \\textbf{  Df Model:          } &        2    \\\\\n",
       "\\textbf{Link Function:}   &      Logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n",
       "\\textbf{Method:}          &       IRLS       & \\textbf{  Log-Likelihood:    } &   -742.42   \\\\\n",
       "\\textbf{Date:}            & Fri, 13 Sep 2024 & \\textbf{  Deviance:          } &    1484.8   \\\\\n",
       "\\textbf{Time:}            &     10:56:27     & \\textbf{  Pearson chi2:      } &  1.09e+03   \\\\\n",
       "\\textbf{No. Iterations:}  &        4         & \\textbf{  Pseudo R-squ. (CS):} &  0.007440   \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       0.2254  &        0.062     &     3.663  &         0.000        &        0.105    &        0.346     \\\\\n",
       "\\textbf{Lag1}  &      -0.0386  &        0.026     &    -1.472  &         0.141        &       -0.090    &        0.013     \\\\\n",
       "\\textbf{Lag2}  &       0.0611  &        0.027     &     2.300  &         0.021        &        0.009    &        0.113     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Generalized Linear Model Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:              Direction   No. Observations:                 1087\n",
       "Model:                            GLM   Df Residuals:                     1084\n",
       "Model Family:                Binomial   Df Model:                            2\n",
       "Link Function:                  Logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -742.42\n",
       "Date:                Fri, 13 Sep 2024   Deviance:                       1484.8\n",
       "Time:                        10:56:27   Pearson chi2:                 1.09e+03\n",
       "No. Iterations:                     4   Pseudo R-squ. (CS):           0.007440\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.2254      0.062      3.663      0.000       0.105       0.346\n",
       "Lag1          -0.0386      0.026     -1.472      0.141      -0.090       0.013\n",
       "Lag2           0.0611      0.027      2.300      0.021       0.009       0.113\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_X = weekly[['Lag1','Lag2']]\n",
    "weekly_X = sm.add_constant(weekly_X)\n",
    "weekly_y = weekly['Direction'] == 'Up'\n",
    "weekly_y = weekly_y.astype(int)\n",
    "weekly_logreg = sm.GLM(weekly_y.loc[2:],weekly_X.loc[2:],family=sm.families.Binomial())\n",
    "weekly_results = weekly_logreg.fit()\n",
    "weekly_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Use the model from (b) to predict the direction of the first observation. You can do this by predicting that the first observation\n",
    "will go up if P(Direction = \"Up\"|Lag1, Lag2) > 0.5. Was this\n",
    "observation correctly classified?\n",
    "\n",
    "- It is classified incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.571988\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_observation = weekly_X.iloc[[0]]\n",
    "weekly_firstobs_pred = weekly_results.predict(first_observation)\n",
    "weekly_firstobs_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Write a for loop from i = 1 to i = n, where n is the number of\n",
    "observations in the data set, that performs each of the following\n",
    "steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Fit a logistic regression model using all but the ith observation to predict Direction using Lag1 and Lag2.\n",
    "\n",
    "ii. Compute the posterior probability of the market moving up\n",
    "for the ith observation.\n",
    "\n",
    "iii. Use the posterior probability for the ith observation in order\n",
    "to predict whether or not the market moves up.\n",
    "\n",
    "iv. Determine whether or not an error was made in predicting\n",
    "the direction for the ith observation. If an error was made,\n",
    "then indicate this as a 1, and otherwise indicate it as a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = np.array([0]*weekly_X.shape[0])\n",
    "n = weekly_X.shape[0]\n",
    "for i in range(n):\n",
    "    train = weekly.index != i\n",
    "    weekly_X = weekly[train][['Lag1','Lag2']]\n",
    "    weekly_X = sm.add_constant(weekly_X)\n",
    "    weekly_X_test = weekly[~train][['Lag1','Lag2']]\n",
    "\n",
    "    weekly_y = weekly[train]['Direction'] == 'Up'\n",
    "    weekly_y = weekly_y.astype(int)\n",
    "    weekly_y_test = weekly[~train]['Direction'] == 'Up'\n",
    "    weekly_logreg = sm.GLM(weekly_y,weekly_X,family=sm.families.Binomial())\n",
    "    weekly_results = weekly_logreg.fit()\n",
    "    weekly_pred = weekly_results.predict(first_observation)\n",
    "    \n",
    "    store[i] = 1 if weekly_pred.iloc[0] > 0.5 and weekly_y_test.iloc[0] == 1 else 0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Take the average of the n numbers obtained in (d)iv in order to\n",
    "obtain the LOOCV estimate for the test error. Comment on the\n",
    "results.\n",
    "\n",
    "- 44.4% test error rate suggests that our model when training with n-1 observations, does not perform well in general. Since our training sets are non-biased because we use n-1 observations, only 55.6% of the time we predicted direction correctly, which is not great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-np.mean(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. We will now perform cross-validation on a simulated data set.\n",
    "\n",
    "(a) Generate a simulated data set as follows:\n",
    "rng = np.random.default_rng(1)\n",
    "x = rng.normal(size=100)\n",
    "y = x - 2 * x**2 + rng.normal(size=100)\n",
    "In this data set, what is n and what is p? Write out the model\n",
    "used to generate the data in equation form.\n",
    "\n",
    "- n is 100, and p is 2, since we have 100 observations and 2 predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1)\n",
    "x = rng.normal(size=100)\n",
    "y = x - 2 * x**2 + rng.normal(size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Create a scatterplot of X against Y . Comment on what you find.\n",
    "\n",
    "- It follows an reversed U-shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2a30df5fdd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Set a random seed, and then compute the LOOCV errors that\n",
    "result from fitting the following four models using least squares:\n",
    "i. Y = β0 + β1X + ϵ\n",
    "ii. Y = β0 + β1X + β2X2 + ϵ\n",
    "iii. Y = β0 + β1X + β2X2 + β3X3 + ϵ\n",
    "iv. Y = β0 + β1X + β2X2 + β3X3 + β4X4 + ϵ.\n",
    "Note you may find it helpful to use the data.frame() function\n",
    "to create a single data set containing both X and Y ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import \\\n",
    "     (cross_validate,\n",
    "      KFold,\n",
    "      ShuffleSplit)\n",
    "from ISLP.models import sklearn_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.86892143, 1.10025092, 1.2791254 , 1.32302942])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'X': x,'y': y})\n",
    "cv_errors = np.zeros(4)\n",
    "model = sklearn_sm(sm.OLS)\n",
    "X = np.empty((len(x), 0))\n",
    "for i in range(1,5):\n",
    "    col =  np.power.outer(x,i).reshape(-1,1)\n",
    "    X = np.concatenate((X,col),axis=1)\n",
    "    cv = cross_validate(model,X,y,cv=x.shape[0])\n",
    "    cv_errors[i-1] = np.mean(cv['test_score'])\n",
    "cv_errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Repeat (c) using another random seed, and report your results.\n",
    "Are your results the same as what you got in (c)? Why?\n",
    "\n",
    "- Roughly the same, because since we constructed y with x^2 we expect it to give lower error with model that uses X and X^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(12)\n",
    "x = rng.normal(size=100)\n",
    "y = x - 2 * x**2 + rng.normal(size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.53152256, 0.98372517, 0.99588538, 1.02501995])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'X': x,'y': y})\n",
    "cv_errors = np.zeros(4)\n",
    "model = sklearn_sm(sm.OLS)\n",
    "X = np.empty((len(x), 0))\n",
    "for i in range(1,5):\n",
    "    col =  np.power.outer(x,i).reshape(-1,1)\n",
    "    X = np.concatenate((X,col),axis=1)\n",
    "    X = sm.add_constant(X)\n",
    "    cv = cross_validate(model,X,y,cv=x.shape[0])\n",
    "    cv_errors[i-1] = np.mean(cv['test_score'])\n",
    "cv_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Which of the models in (c) had the smallest LOOCV error? Is\n",
    "this what you expected? Explain your answer.\n",
    "\n",
    "- The model that has both x and x^2 gave the lowest LOOCV error, it expected as while creating y we used x and x^2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Comment on the statistical significance of the coefficient estimates that results from fitting each of the models in (c) using\n",
    "least squares. Do these results agree with the conclusions drawn\n",
    "based on the cross-validation results?\n",
    "\n",
    "- Yes, as x and x^2 is statistically significant on the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.172\n",
      "Model:                            OLS   Adj. R-squared:                  0.163\n",
      "Method:                 Least Squares   F-statistic:                     20.29\n",
      "Date:                Fri, 13 Sep 2024   Prob (F-statistic):           1.84e-05\n",
      "Time:                        11:27:50   Log-Likelihood:                -223.64\n",
      "No. Observations:                 100   AIC:                             451.3\n",
      "Df Residuals:                      98   BIC:                             456.5\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.7058      0.229     -7.447      0.000      -2.160      -1.251\n",
      "x1             1.1297      0.251      4.505      0.000       0.632       1.627\n",
      "==============================================================================\n",
      "Omnibus:                       22.111   Durbin-Watson:                   2.016\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               29.546\n",
      "Skew:                          -1.094   Prob(JB):                     3.84e-07\n",
      "Kurtosis:                       4.519   Cond. No.                         1.11\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.849\n",
      "Model:                            OLS   Adj. R-squared:                  0.845\n",
      "Method:                 Least Squares   F-statistic:                     271.7\n",
      "Date:                Fri, 13 Sep 2024   Prob (F-statistic):           1.76e-40\n",
      "Time:                        11:27:50   Log-Likelihood:                -138.68\n",
      "No. Observations:                 100   AIC:                             283.4\n",
      "Df Residuals:                      97   BIC:                             291.2\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0271      0.127     -0.213      0.832      -0.280       0.225\n",
      "x1             0.9272      0.108      8.568      0.000       0.712       1.142\n",
      "x2            -2.0018      0.096    -20.822      0.000      -2.193      -1.811\n",
      "==============================================================================\n",
      "Omnibus:                        0.367   Durbin-Watson:                   1.831\n",
      "Prob(Omnibus):                  0.833   Jarque-Bera (JB):                0.113\n",
      "Skew:                          -0.065   Prob(JB):                        0.945\n",
      "Kurtosis:                       3.102   Cond. No.                         2.26\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.849\n",
      "Model:                            OLS   Adj. R-squared:                  0.844\n",
      "Method:                 Least Squares   F-statistic:                     179.4\n",
      "Date:                Fri, 13 Sep 2024   Prob (F-statistic):           3.18e-39\n",
      "Time:                        11:27:50   Log-Likelihood:                -138.65\n",
      "No. Observations:                 100   AIC:                             285.3\n",
      "Df Residuals:                      96   BIC:                             295.7\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0224      0.129     -0.174      0.862      -0.279       0.234\n",
      "x1             0.8829      0.203      4.346      0.000       0.480       1.286\n",
      "x2            -2.0038      0.097    -20.676      0.000      -2.196      -1.811\n",
      "x3             0.0210      0.081      0.258      0.797      -0.140       0.182\n",
      "==============================================================================\n",
      "Omnibus:                        0.390   Durbin-Watson:                   1.826\n",
      "Prob(Omnibus):                  0.823   Jarque-Bera (JB):                0.125\n",
      "Skew:                          -0.067   Prob(JB):                        0.939\n",
      "Kurtosis:                       3.109   Cond. No.                         5.30\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.851\n",
      "Model:                            OLS   Adj. R-squared:                  0.844\n",
      "Method:                 Least Squares   F-statistic:                     135.3\n",
      "Date:                Fri, 13 Sep 2024   Prob (F-statistic):           2.48e-38\n",
      "Time:                        11:27:50   Log-Likelihood:                -137.98\n",
      "No. Observations:                 100   AIC:                             286.0\n",
      "Df Residuals:                      95   BIC:                             299.0\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0753      0.155      0.485      0.629      -0.233       0.384\n",
      "x1             0.9513      0.212      4.492      0.000       0.531       1.372\n",
      "x2            -2.3105      0.289     -7.996      0.000      -2.884      -1.737\n",
      "x3            -0.0165      0.088     -0.189      0.851      -0.190       0.157\n",
      "x4             0.0876      0.078      1.127      0.263      -0.067       0.242\n",
      "==============================================================================\n",
      "Omnibus:                        0.241   Durbin-Watson:                   1.781\n",
      "Prob(Omnibus):                  0.887   Jarque-Bera (JB):                0.076\n",
      "Skew:                          -0.065   Prob(JB):                        0.963\n",
      "Kurtosis:                       3.037   Cond. No.                         14.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'X': x,'y': y})\n",
    "results = np.zeros(4)\n",
    "model = sklearn_sm(sm.OLS)\n",
    "X = np.empty((len(x), 0))\n",
    "for i in range(1,5):\n",
    "    col =  np.power.outer(x,i).reshape(-1,1)\n",
    "    X = np.concatenate((X,col),axis=1)\n",
    "    X = sm.add_constant(X)\n",
    "    result = sm.OLS(y,X).fit()\n",
    "    print(result.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. We will now consider the Boston housing data set, from the ISLP\n",
    "library.\n",
    "\n",
    "(a) Based on this data set, provide an estimate for the population\n",
    "mean of medv. Call this estimate µˆ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
       "       'ptratio', 'lstat', 'medv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = load_data('Boston')\n",
    "boston.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.532806324110677"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medv_mean = np.mean(boston.medv)\n",
    "medv_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Provide an estimate of the standard error of µˆ. Interpret this\n",
    "result.\n",
    "\n",
    "Hint: We can compute the standard error of the sample mean by\n",
    "dividing the sample standard deviation by the square root of the\n",
    "number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4084569346972866"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medv_mean_std = np.std(boston.medv) / np.sqrt(boston.shape[0])\n",
    "medv_mean_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Now estimate the standard error of µˆ using the bootstrap. How\n",
    "does this compare to your answer from (b)?\n",
    "- Little bit higher, but close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_mean(D, idx):\n",
    "    D_ = D.loc[idx]\n",
    "    Y_ = D_['medv']\n",
    "    return np.mean(Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_SE(func,D,n=None,B=10000,seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_ , second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index ,\n",
    "        n,\n",
    "        replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "    return np.sqrt(second_ / B - (first_ / B)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41253476750888246"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_SE = boot_SE(boot_mean,boston,B=1000,seed=0)\n",
    "alpha_SE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Based on your bootstrap estimate from (c), provide a 95 % confidence interval for the mean of medv. Compare it to the results\n",
    "obtained by using Boston['medv'].std() and the two standard\n",
    "error rule (3.9).\n",
    "Hint: You can approximate a 95 % confidence interval using the\n",
    "formula [ˆ µ − 2SE(ˆ µ), µˆ + 2SE(ˆ µ)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21.707736789092912, 23.35787585912844]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_int = [medv_mean- 2*alpha_SE, medv_mean+2*alpha_SE]\n",
    "conf_int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21.715892454716105, 23.34972019350525]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_int_2 = [medv_mean- 2*medv_mean_std, medv_mean+2*medv_mean_std]\n",
    "conf_int_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Based on this data set, provide an estimate, µˆmed, for the median\n",
    "value of medv in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_median(D, idx):\n",
    "    D_ = D.loc[idx]\n",
    "    Y_ = D_['medv']\n",
    "    return np.median(Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot(func,D,n=None,B=10000,seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_ = 0\n",
    "    n = n or D.shape[0]\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index ,\n",
    "        n,\n",
    "        replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "    return first_ / B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.18400000000019"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medv_median_estimate = boot(boot_median,boston)\n",
    "medv_median_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) We now would like to estimate the standard error of µˆmed. Unfortunately, there is no simple formula for computing the standard\n",
    "error of the median. Instead, estimate the standard error of the\n",
    "median using the bootstrap. Comment on your findings.\n",
    "\n",
    "-0.37. Since standart is relatively small, it suggests that median is fairly close to population median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37687862766090385"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medv_median_std_estimate = boot_SE(boot_median,boston)\n",
    "medv_median_std_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) Based on this data set, provide an estimate for the tenth percentile of medv in Boston census tracts. Call this quantity µˆ0.1.\n",
    "(You can use the np.percentile() function.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_perc(D, idx):\n",
    "    D_ = D.loc[idx]\n",
    "    Y_ = D_['medv']\n",
    "    return np.percentile(Y_,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.291792949999952"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medv_tenth_perc = boot(boot_perc,boston)\n",
    "medv_tenth_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(h) Use the bootstrap to estimate the standard error of µˆ0.1. Comment on your findings.\n",
    "\n",
    "- the std error is 0.46, and median standart error was 0.37, this suggests tenth percentile is less stable compared to median.  This is likely because the extreme values like 10th percentile are more likely to get influence from outliers, compared to median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46969632913822457"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medv_tent_perc_std = boot_SE(boot_perc,boston)\n",
    "medv_tent_perc_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

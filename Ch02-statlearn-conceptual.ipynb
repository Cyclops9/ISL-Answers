{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Statistical Learning\n",
    "Excercises from Chapter 2 of An Introduction to Statistical Learning by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptual\n",
    "Q1\n",
    "For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.\n",
    "\n",
    "(a) The sample size n is extremely large, and the number of predictors p is small.\n",
    "    - Flexible, because number of sample is big to avoid overfitting.\n",
    "(b) The number of predictors p is extremely large, and the number\n",
    "of observations n is small.\n",
    "    - Inflexible, because small number of observations can cause overfitting.\n",
    "(c) The relationship between the predictors and response is highly\n",
    "non-linear.\n",
    "    - Flexible, as introducing inflexible method could cause high bias.\n",
    "(d) The variance of the error terms, i.e. σ2 = Var(ϵ), is extremely\n",
    "high.\n",
    "    - Inflexible, as flexible methods will cause overfitting and cause incorrect results because of high variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide n and p.\n",
    "(a) We collect a set of data on the top 500 firms in the US. For each\n",
    "firm we record profit, number of employees, industry and the\n",
    "CEO salary. We are interested in understanding which factors\n",
    "affect CEO salary.\n",
    "    - regression, inference,n = 500, p = 4\n",
    "(b) We are considering launching a new product and wish to know\n",
    "whether it will be a success or a failure. We collect data on 20\n",
    "similar products that were previously launched. For each product we have recorded whether it was a success or failure, price\n",
    "charged for the product, marketing budget, competition price,\n",
    "and ten other variables.\n",
    "    - classification, prediction, n = 20, p = 14\n",
    "(c) We are interested in predicting the % change in the USD/Euro\n",
    "exchange rate in relation to the weekly changes in the world\n",
    "stock markets. Hence we collect weekly data for all of 2012. For\n",
    "each week we record the % change in the USD/Euro, the %\n",
    "change in the US market, the % change in the British market,\n",
    "and the % change in the German market.\n",
    "    - regression, prediction, n = 52, p = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now revisit the bias-variance decomposition.\n",
    "(a) Provide a sketch of typical (squared) bias, variance, training error, test error, and Bayes (or irreducible) error curves, on a single plot, as we go from less flexible statistical learning methods\n",
    "towards more flexible approaches. The x-axis should represent\n",
    "the amount of flexibility in the method, and the y-axis should\n",
    "represent the values for each curve. There should be five curves.\n",
    "Make sure to label each one.\n",
    "    ![image1](image1.png \"Error-Rate vs Flexibility\")\n",
    "(b) Explain why each of the five curves has the shape displayed in\n",
    "part (a).\n",
    "    - Test error rate follows U-shape because as flexibility increases we can reduce test error but afterwards we can easily overfit the model to train data which causes increase in test error rate. And test error is always higher than bayes error because, it consist of irreducible error (bayes), and reducible error.\n",
    "    - Bayes error is irreducible error coming from making an assumption of the model, i.e., linear, and its irreducible because there will be always an error because of the assumption. And its not related to model flexibility.\n",
    "    - Variance error rate increases as flexibility increases because we overfit the model.\n",
    "    - Bias decreases because we make more correct assumptions depending on the data.\n",
    "    - Training error always decreases because we overfit the model to training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. You will now think of some real-life applications for statistical learning.\n",
    "(a) Describe three real-life applications in which classification might\n",
    "be useful. Describe the response, as well as the predictors. Is the\n",
    "goal of each application inference or prediction? Explain your\n",
    "answer.\n",
    "    - Classifying if a patient has a chance of a disease according to symptoms, prediction.\n",
    "    - Classifying a match as win or lose depending of previous matches of the team, prediction.\n",
    "    - Classifying a match as win or lose depending of previous matches to infer what affects the team performance, predictors can be star players, injuries etc.\n",
    "(b) Describe three real-life applications in which regression might\n",
    "be useful. Describe the response, as well as the predictors. Is the\n",
    "goal of each application inference or prediction? Explain your\n",
    "answer.\n",
    "    - Predicting a house value depending on its features, balcony, number of rooms, area etc.\n",
    "    - Infering what is affecting a house's value.\n",
    "    - Predicting a salary of an applicant depending of skills he/her have.\n",
    "(c) Describe three real-life applications in which cluster analysis\n",
    "might be useful.\n",
    "    - Estimating which observations belong together on predicting flower species, depending on petal, sepal length, num of petals\n",
    "    - Inferring which features are most predictive on specifying the species.\n",
    "    - Grouping audio samples to make prediction about new ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What are the advantages and disadvantages of a very flexible (versus\n",
    "a less flexible) approach for regression or classification? Under what\n",
    "circumstances might a more flexible approach be preferred to a less\n",
    "flexible approach? When might a less flexible approach be preferred?\n",
    "    - Flexible approaches might get overfit with the training data if number of samples are not a lot. When there is little sample, less flexible methods should be preffered, however large samples can avoid overfit with flexible methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Describe the differences between a parametric and a non-parametric\n",
    "statistical learning approach. What are the advantages of a parametric approach to regression or classification (as opposed to a nonparametric approach)? What are its disadvantages?\n",
    "    - Difference: Parametric approach makes an assumption of functional form of the data, non-parametric approach does not make assumption.\n",
    "    - Advantages of parametric approach: \n",
    "        - Faster,\n",
    "        - Avoids overfitting,\n",
    "    - Disadvantages\n",
    "        - Might underfit,\n",
    "        - Performs badly if assumption is biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. The table below provides a training data set containing six observations, three predictors, and one qualitative response variable.\n",
    "Obs. X1 X2  X3 Y\n",
    "1   0   3   0 Red\n",
    "2   2   0   0 Red\n",
    "3   0   1   3 Red\n",
    "4   0   1   2 Green\n",
    "5   −1  0   1 Green\n",
    "6   1   1   1 Red\n",
    "Suppose we wish to use this data set to make a prediction for Y when\n",
    "X1 = X2 = X3 = 0 using K-nearest neighbors.\n",
    "(a) Compute the Euclidean distance between each observation and\n",
    "the test point, X1 = X2 = X3 = 0.\n",
    "(b) What is our prediction with K = 1? Why?\n",
    "(c) What is our prediction with K = 3? Why?\n",
    "(d) If the Bayes decision boundary in this problem is highly nonlinear, then would we expect the best value for K to be large or\n",
    "small? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 2.0, 3.1622776601683795, 2.23606797749979, 1.4142135623730951, 1.7320508075688772]\n"
     ]
    }
   ],
   "source": [
    "# (a) Compute the Euclidean distance between each observation and the test point, X1 = X2 = X3 = 0.\n",
    "X = [[0,3,0],[2,0,0],[0,1,3],[0,1,2],[-1,0,1],[1,1,1]]\n",
    "# y = red       red     red     green   green   red\n",
    "test_point = [0,0,0]\n",
    "result = list()\n",
    "for i in range(len(X)):\n",
    "    dist = 0\n",
    "    for j in range(len(X[i])):\n",
    "        dist += (X[i][j] - test_point[j])**2\n",
    "    result.append(dist**0.5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) What is our prediction with K = 1? Why?\n",
    "    - Green, because test point is closest to green\n",
    "(c) What is our prediction with K = 3? Why?\n",
    "    - Red, because 2 of 3 predictions that is closest is red\n",
    "(d) If the Bayes decision boundary in this problem is highly nonlinear, then would we expect the best value for K to be large or\n",
    "small? Why?\n",
    "    - Small, because non-linear relationship can cause incorrect result with large K."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
